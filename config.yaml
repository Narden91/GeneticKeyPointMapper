settings:
  verbose: 0 # 0: minimal, 1: basic 2: extended
  global_random_seed: 42

# --- POSE RETARGETING ---
pose_retargeting:
  data_base_path: "data/" # Base path 
  source_keypoints_file_suffix: "__KP3D.csv"
  target_keypoints_file_suffix: "__AL.csv"
  source_num_keypoints: 33
  target_num_keypoints: 54
  
  # Movement Filtering:
  # Provide a list of exact movement identifiers as found in the filenames.
  # The code will extract the part of the filename like "F-JUMP", "A-POSE", "F_J-JACKS"
  # movement_filter: ["F-JUMP"]                 # Only standard jumps
  # movement_filter: ["F-JUMP", "F_T-JUMP"]     # Standard jumps and T-jumps
  # movement_filter: ["A-POSE", "F-GAIT", "F-RUNNING"]
  # movement_filter: []                         # Load all movements
  movement_filter: ["GAIT"] 
  
  # Subject-based train/test split
  # Option 1: Ratio (subjects will be randomly split)
  # train_subject_ratio: 0.8 
  # Option 2: Explicit lists 
  train_subjects: ["TDB_001_F", "TDB_002_F", "TDB_003_M", "TDB_005_F", "TDB_006_M", "TDB_007_M", "TDB_008_M", "TDB_009_M", "TDB_010_F", "TDB_012_M", "TDB_013_M", "TDB_014_M", "TDB_015_M", "TDB_016_M", "TDB_017_F", "TDB_018_M", "TDB_019_M", "TDB_020_F", "TDB_021_M", "TDB_022_M", "TDB_023_M", "TDB_024_F", "TDB_025_F", "TDB_026_M", "TDB_027_F", "TDB_029_F", "TDB_030_M", "TDB_031_F", "TDB_033_F", "TDB_034_M", "TDB_036_F", "TDB_039_F", "TDB_040_F", "TDB_043_F", "TDB_044_F", "TDB_045_F", "TDB_046_F", "TDB_047_F", "TDB_048_F", "TDB_062_F", "TDB_063_F", "TDB_064_F", "TDB_065_M", "TDB_066_F", "TDB_067_F", "TDB_068_F", "TDB_069_M", "TDB_070_M", "TDB_050_F", "TDB_051_M", "TDB_052_M", "TDB_054_F", "TDB_056_M", "TDB_057_M", "TDB_058_M", "TDB_059_M", "TDB_060_M"]
  test_subjects: ["TDB_004_F", "TDB_011_M", "TDB_028_M", "TDB_032_F", "TDB_035_F", "TDB_037_M", "TDB_038_M", "TDB_041_F", "TDB_042_F", "TDB_049_F", "TDB_053_M", "TDB_055_M", "TDB_061_M", "TDB_071_F"]

  preprocessing:
    normalization_range: [0, 1] # (min, max) for coordinate scaling, or null to skip
    # outlier_filter: "median" # "savitzky_golay" or null 
    # missing_data_method: "linear_interpolate" # or "cubic_spline" 

genome_definition:
  C1_init_bounds: [0, 1]  # For correspondence matrix
  S_init_bounds: [0.5, 1.5] # For scaling factors
  B_init_bounds: [-0.2, 0.2] # For bias vectors

nsga3_optimizer:
  population_size: 10 # Start small
  num_generations: 10 # Start small
  crossover_prob: 0.9
  crossover_eta: 15 # For SBX
  mutation_prob: 0.1 # Per-variable mutation probability
  mutation_eta: 20  # For Polynomial Mutation

  # Weights for objectives (not used by NSGA-III directly, but for final selection or if simplifying to single objective later)
  objective_weights:
    accuracy: 1.0
    temporal_consistency: 0.5
    # anatomical_plausibility: 0.2 # For future ?

model:
  type: LogisticRegression  # Options: RandomForest, XGBoost, CatBoost, LogisticRegression
  global_random_state: 42

  LogisticRegression_params:
    C: 1.0
    solver: 'lbfgs'  # For multiclass problems
    multi_class: 'multinomial'  # For multiclass problems
    max_iter: 1000
    # penalty: 'l2'  # default
    # class_weight: 'balanced'  # Optional for imbalanced classes

  RandomForest_params:
    n_estimators: 100
    max_depth: 5 # null means no limit or use scikit-learn default
    # min_samples_split: 2
    # min_samples_leaf: 1
    # random_state: 42 # Overrides global_random_state

  XGBoost_params:
    n_estimators: 100
    learning_rate: 0.1
    # max_depth: 3
    # subsample: 0.8
    # colsample_bytree: 0.8
    # objective: 'multi:softprob' # Auto-set: 'multi:softprob' for multiclass, 'binary:logistic' for binary
    # eval_metric: 'mlogloss'     # Auto-set: 'mlogloss' for multiclass, 'logloss' for binary
    # use_label_encoder: false    # Auto-set to False
    # random_state: 42            # Overrides global_random_state
    
  CatBoost_params:
    iterations: 200 # Equivalent to n_estimators
    learning_rate: 0.05
    # depth: 6
    # l2_leaf_reg: 3
    # loss_function: 'MultiClass' # Auto-set: 'MultiClass' for multiclass, 'Logloss' for binary
    # verbose: 0                  # Auto-set to 0 (silent) unless specified
    # random_seed: 42             # Overrides global_random_state (CatBoost uses random_seed)

cross_validation:
  n_splits: 5
  shuffle: True
  # random_state: 42 # Optional: uses model.global_random_state by default if not set here

calibration:
  enabled: False # Set to True to enable calibration
  default_method: "isotonic" # Fallback if specific model method not found
  randomforest_method: "isotonic" # or "sigmoid"
  xgboost_method: "isotonic"
  catboost_method: "isotonic" 

explainer:
  shap:
    enabled: False # Set to True to enable SHAP explanations
    summary_plot_path: "reports/shap_summary_plot.png" # Path to save SHAP summary plot
    # Add other SHAP specific parameters if your explainer.py uses them

bayesian_methods:
  params:
    alpha: 1.0
    beta: 1.0